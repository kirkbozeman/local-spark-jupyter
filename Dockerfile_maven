FROM ubuntu:18.04
#FROM ubuntu:20.04
#FROM python:3.10-slim-buster
#FROM alpine:3.10

USER root

ARG DEBIAN_FRONTEND=noninteractive

ARG MAVEN_OPTS="-Xss64m -Xmx2g -XX:ReservedCodeCacheSize=1g"
ARG openjdk_version="11"
ARG python_version="3.9"

ARG spark_version="3.2.0-rc7"
ARG hadoop_version="3.3.1"

#    apt-get upgrade -y && \

RUN apt-get update -y && \
    apt-get upgrade -y && \
    apt-get install -y \
    "openjdk-${openjdk_version}-jre-headless" \
    software-properties-common \
    curl wget vim git scala maven \
    ca-certificates-java

# install desired python and set symlink
RUN add-apt-repository ppa:deadsnakes/ppa -y
RUN apt install -y python${python_version} \
        python${python_version}-dev python${python_version}-venv && \
        rm /usr/bin/python3 && ln -s $(which python${python_version}) /usr/bin/python3

# install python libs
ADD docker/requirements.txt /root/
RUN apt install -y python3-pip python3-setuptools && \
    pip3 install --upgrade pip && \
    pip3 install -r /root/requirements.txt

# Spark installation from local tgz
#ADD docker/spark-3.2.0-bin-hadoop3.2.tgz /tmp/
#RUN cp -a /tmp/spark-3.2.0-bin-hadoop3.2/. /usr/local/spark/ && \
#    rm -r /tmp/spark-3.2.0-bin-hadoop3.2

WORKDIR /usr/local

RUN git clone --depth 1 --branch v${spark_version} https://github.com/apache/spark.git spark && \
    cd spark && \
    ./dev/make-distribution.sh --pip --r --tgz  \
        -Phive -Phive-thriftserver  \
        -Dhadoop.version=${hadoop_version} \
        -Pyarn

#        -Psparkr  \

#    ./build/mvn -DskipTests clean package \

# add test files
ADD docker/vimas_merchant_address_20200825_003122.csv.gz /tmp/test.csv.gz
ADD docker/test_nb.ipynb /local/usr/jupyter-notebooks/test_nb.ipynb


EXPOSE 8890
EXPOSE 8080

COPY docker/bootstrap.sh /root/
RUN chmod +x /root/bootstrap.sh
#ENTRYPOINT ["/root/bootstrap.sh"]
ENTRYPOINT ["tail", "-f", "/dev/null"]
